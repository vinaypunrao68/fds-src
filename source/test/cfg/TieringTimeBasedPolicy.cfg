#
# Copyright 2015 Formation Data Systems, Inc.
#
# TEST RESOURCES and TOPOLOGY
[user]
user_name       = root
password        = passwd

# The 'node' section defines a nodes paramters. The section must be prefixed
# with 'node' but is also used as a unique ID for the node.
#
[node1]
# Denotes this node will run an OM. Therefore, it is enabled automatically.
om              = true
# We'll start Redis with this node. Since all the other nodes listed
# here are on the same machine, we don't need to specify Redis for
# boot up on them.
redis           = true
# start influxdb
influxdb        = false
# IP of the node
ip              = localhost
# Fds root directory to use
fds_root        = /fds/node1
# Base port for that node, not needed if we don't run all nodes one physical machine
fds_port        = 7000
# By default we get all services on a node. Otherwise we' specify a 'services' option.

[node2]
enable          = true
ip              = localhost
fds_root        = /fds/node2
fds_port        = 7100
services        = dm,sm

[node3]
enable          = true
ip              = localhost
fds_root        = /fds/node3
fds_port        = 7200
services        = dm,sm

[node4]
enable          = true
ip              = localhost
fds_root        = /fds/node4
fds_port        = 7300
services        = dm,sm


# The 'policy' section defines a volume policy
#
[policy1]
# The ID of the policy
id    = 1
# iops_min of the policy
iops_min = 100
# iops_max of the policy
iops_max = 500
# priority of the policy
priority = 1

# The 'volume' section defines a volume
[volume1]
# Name of the server AM node to attach to
client = node1
# The ID of the volume. Apparently ignored by the FDS system which assigns what it wants.
id     = 1
# The size of the volume
size   = 10000
# A policy ID for the volume, must be defined in the 'policy' section
policy = 1
# The volume access type, currenty either 'object' or 'block'
access = object
# Set hybrid media policy
media  = hybrid

# TEST STEPS or CASES or SCENARIOS
# Will be ordered according to scenario name.

[scenario_0_1]
log_marker      = Install domain
script          = [domain]
action          = install


[scenario_0_2]
log_marker      = Change platform.conf tiering settings
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string
params          = frequency\s*= 604800,frequency = 420

[scenario_0_2_1]
log_marker      = Change platform.conf AM cache sizes to 0
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string
params          = max_volume_data\s*=\s*400,max_volume_data = 0

[scenario_0_2_2]
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string
params          = max_metadata_entries\s*=\s*200,max_metadata_entries = 0

[scenario_0_2_3]
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string
params          = tx_max_staged_entries = 10,tx_max_staged_entries = 0

[scenario_0_3]
log_marker      = boot and activate domain
script          = [domain]
action          = boot-activate

[scenario_0_4]
# Verify nodes node1-4 are up
log_marker      = VERIFY ALL NODES CURRENTLY UP AND ACTIVE
script          = [verify]
state           = up

[scenario_0_6]
# Create volume volume1
log_marker      = Create volume
script          = [volume1]
action          = create
delay_wait      = 10

[scenario_0_7]
# Attach volume volume1
log_marker      = Attach volume
script          = [volume1]
action          = attach

[scenario_0_8]
# Get an S3 authorization token
log_marker      = Get S3 auth token
script          = [testcases.TestOMIntFace.TestGetAuthToken]

[scenario_0_9]
# Get an S3 connection
log_marker      = Get S3 connection
script          = [testcases.TestS3IntFace.TestS3GetConn]


[scenario_1]
log_marker      = Get initial counter values for comparison
script          = [testcases.TestIOCounter.VerifyAggregateIOCounters]
param_names     = counter,expected_value
params          = SM_OBJ_DATA_SSD_WRITE.volume:1:volume=1,0

[scenario_1_1]
# Run some IO
log_marker      = Run PUT Test
script          = [testcases.TrafficGen.TestTrafficGen]
param_names     = hostname,n_files,test_type,username,volume_name,n_reqs
params          = localhost,100,PUT,admin,volume1,100


[scenario_1_2]
log_marker      = Get post-PUT counter values for comparison
script          = [testcases.TestIOCounter.VerifyAggregateIOCounters]
param_names     = counter,expected_value
params          = SM_OBJ_DATA_SSD_WRITE.volume:1:volume=1,400

[scenario_1_3]
# Run some IO
log_marker      = Run GET test
script          = [testcases.TrafficGen.TestTrafficGen]
param_names     = hostname,n_files,test_type,username,volume_name,n_reqs
params          = localhost,100,GET,admin,volume1,100


[scenario_1_3_1]
log_marker      = Get post-GET counter values for comparison
script          = [testcases.TestIOCounter.VerifyAggregateIOCounters]
param_names     = counter,expected_value
params          = SM_OBJ_DATA_SSD_READ.volume:1:volume=1,100
delay_wait      = 600


[scenario_1_3_2]
# Run some IO
log_marker      = Run SECOND GET test
script          = [testcases.TrafficGen.TestTrafficGen]
param_names     = hostname,n_files,test_type,username,volume_name,n_reqs
params          = localhost,100,GET,admin,volume1,100


[scenario_1_4]
log_marker      = Get post-GET SSD read counters
script          = [testcases.TestIOCounter.VerifyAggregateIOCounters]
param_names     = counter,expected_value
params          = SM_OBJ_DATA_SSD_READ.volume:1:volume=1,100


[scenario_2]
log_marker      = Cleanup from test.
script          = [domain]
action          = kill-uninst
delay_wait      = 120
